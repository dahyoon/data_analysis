{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단순 선형 회귀 (학습 성능 개선)\n",
    "- 텐서플로우의 학습성능을 개선하기 위해 아래의 기능을 사용할 수 있음\n",
    "1. `데이터 표준화`: 학습률 향상에 도움을 줌\n",
    "2. `콜백 함수`: 모델의 학습 방향, 저장 시점, 학습 정지 시점 등에 관한 상황을 모니터링하기 위한 도구\n",
    "\n",
    "## 1. 데이터 정규화 (Normalization)\n",
    "### 1) 데이터 정규화의 이해\n",
    "- 데이터 정규화란? \n",
    "    - 모든 데이터가 동일한 정도의 스케일(중요도)로 반영되도록 해주는 처리\n",
    "- 정규화를 해야하는 이유\n",
    "    - 머신러닝 알고리즘은 데이터가 가진 feature(특성)들을 비교하여 데이터의 패턴을 찾는다\n",
    "    - 이 때, 데이터가 가진 feature의 스케일이 심하게 차이가 나는 경우 수많은 학습단계를 거쳐 최적값에 도달하게 된다\n",
    "    - 데이터에 `정규화 처리를 적용`하면 `쉽게 최적값에 도달`할 수 있으며 `학습률을 상대적으로 높여서 사용`할 수 있기 때문에 빠르게 훈련시킬 수 있다.\n",
    "\n",
    "### 2) 데이터 정규화 방법\n",
    "#### 1- 최소-최대 정규화 (Min-Max Normalization)\n",
    "- 모든 feature에 대해 각각의 `최솟값 0`, `최대값 1`로, 그리고 `다른 값들은 0과 1 사이의 값`으로 변환\n",
    "- 예) 어떤 특성의 `최솟값이 20`이고 `최대값이 40`인 경우, 30이라는 데이터가 있을 경우, 20은 `0`, 40은 `1`로 환산되기 때문에 30은 중간치인 `0.5`로 변환됨\n",
    "\n",
    "## 2. 콜백함수\n",
    "- 모델의 학습 방향, 저장 시점, 학습 정지 시점 등에 관한 상황을 모니터링하기 위한 도구\n",
    "### 1) 콜백함수 사용 방법\n",
    "- 콜백 정의\n",
    "\n",
    "    ```python\n",
    "    callbacks = [  콜백1, 콜백2, ... 콜백n  ]\n",
    "    ```\n",
    "- 학습을 위한 `fit() 함수`에서 `callbacks 파라미터`에 미리 정의한 리스트를 지정\n",
    "\n",
    "    ```python\n",
    "    callbacks = [콜백1, 콜백2, ..., 콜백n]\n",
    "    model.fit(x_train, \n",
    "              y_train, \n",
    "              validation_data = (x_val, y_val), \n",
    "              epochs = 500, \n",
    "              callbacks=callbacks)```\n",
    "- 혹은\n",
    "\n",
    "    ```python\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              validation_data = (x_val, y_val),\n",
    "              epochs = 500,\n",
    "              callbacks = [콜백1, 콜백2, ..., 콜백n])```\n",
    "\n",
    "### 2) 콜백함수 종류\n",
    "#### 1- EarlyStopping()\n",
    "- 모델 학습 시에 지정된 기간 동안 모니터링하는 평가지표에서 더 이상 성능 향상이 일어나지 않는 경우 학습을 스스로 중단\n",
    "\n",
    "    ```python\n",
    "    EarlyStopping(monitor='평가지표', patience=10, verbose=1)```\n",
    "\n",
    "- patience: 지정한 수만큼의 기간에서 평가지표의 향상이 일어나지 않을 경우 학습을 중단 (기간=에폭)\n",
    "    - 예) `patience=10`일 때, 10에폭 동안 성능 향상이 일어나지 않으면 학습을 중단. 즉, `10회 이상 성능향상이 발견되지 않으면 중단`\n",
    "- verbose: 콜백의 수행 과정 노출 여부를 지정\n",
    "    - 0: 아무런 표시 하지 않음(기본값)\n",
    "    - 1: 프로그래스바로 표시\n",
    "    - 2: 매 에폭마다 수행과정을 자세하게 출력함\n",
    "#### 2- ReduceLROnPlateau()\n",
    "- EarlyStopping 콜백과 같이 patience 인자를 지정하여, 지정된 기간 동안 평가지표에서 성능 향상이 일어나지 않으면 학습률을 조정하는 콜백\n",
    "\n",
    "    ```python\n",
    "    ReduceLROnPlateau(monitor='평가지표', factor=0.1,\n",
    "                      patience=10, min_lr=0, verbose=1)```\n",
    "\n",
    "- factor: 학습률 조정에 사용되는 값 (새로운 학습률 = factor  * 기존 학습률)\n",
    "- patience: 지정한 수만큼의 기간에서 성능 향상이 일어나지 않을 경우, 학습률을 조정\n",
    "- min_lr: 학습률의 하한 (lower limit)을 지정\n",
    "- verbose: 콜백의 수행 과정 노출 여부를 지정\n",
    "#### 3- ModelCheckpoint()\n",
    "- 지정한 평가지표를 기준으로 `가장 뛰어난 성능을 보여주는 모델을 저장` 할 때 사용\n",
    "\n",
    "    ```python\n",
    "    ModelCheckpoint(filepath, monitor='평가지표', verbose=1,\n",
    "                    save_best_only = True|False, save_weights_only = False)```\n",
    "- filepath: 모델의 저장 경로를 지정\n",
    "- save_best_only: True인 경우, 가장 성능이 뛰어난 모델만 저장. 그보다 좋지 않은 모델의 경우는 덮어쓰지 않음\n",
    "- save_weights_only: 모델의 가중치만 저장\n",
    "## 3. 단순선형회귀 수행\n",
    "### 1) 패키지 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../../')\n",
    "\n",
    "from pandas import read_excel, DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "\n",
    "# 데이터를 훈련용과 테스트용으로 나누는 기능\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 정규화를 위한 패키지\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 순서층을 구성하는 모델 객체 생성 기능\n",
    "from tensorflow.keras.models import Sequential\n",
    "# 모델 객체에 학습층을 쌓기 위한 클래스\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 학습에 대한 콜백함수 참조\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = read_excel('https://data.hossam.kr/E04/cars.xlsx')\n",
    "origin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 데이터 전처리\n",
    "- 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측치 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 탐색적 데이터 분석\n",
    "- 기본통계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 산점도 그래프와 추세선 확인\n",
    "    - `seaborn.regplot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sb.regplot(data=origin, x='speed', y='dist', color='orange')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 곡선보다는 선형 분포에 더 가까우므로 단순선형회귀모델을 적용하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 데이터셋 분할\n",
    "- 랜덤시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m777\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 데이터(독립변수)와 레이블(종속변수) 구분하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = origin.drop(['dist'], axis = 1)\n",
    "y = origin[['dist']]\n",
    "print('훈련데이터 크기:', x.shape, '/ 레이블 크기:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (추가) 데이터 정규화(표준화) 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수 표준화\n",
    "x_scaler = MinMaxScaler()\n",
    "x_scale = x_scaler.fit_transform(x)\n",
    "x_scale\n",
    "\n",
    "# 종속변수 표준화\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scale = y_scaler.fit_transform(y)\n",
    "y_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 데이터와 검증 데이터로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ᄐ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ㅌ\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ᄐ' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scale, \n",
    "                                                    y_scale, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state=777)\n",
    "print('훈련용 데이터셋 크기: %d, 검증용 데이터셋 크기: %d' % (len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 모델 개발\n",
    "- 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Sequential()\n",
    "# 1차원의 데이터를 입력으로 받고, 32개의 출력을 가지는 첫 번때 Dense 층\n",
    "my_model.add(Dense(32, activation = 'relu', input_shape = (1,)))\n",
    "# 하나의 값을 출력\n",
    "# -> 정답의 범위가 정해지지 않기 때문에 활성화 함수는 linear\n",
    "# -> linear는 기본값이므로 생략 가능\n",
    "my_model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "my_model.compile(optimizer='adam', \n",
    "                 loss='mse',\n",
    "                 metrics=['mae'])\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[39m.\u001b[39mgetcwd()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = my_model.fit(x_train, y_train, epochs=500, validation_data=(x_test,y_test))\n",
    "# 파일이 저장될 경로(폴더) 지정 (한글, 공백, 점(.)이 포함되어 잇을 경우 에러 발생함)\n",
    "\n",
    "checkpoint_path = os.path.join('D:\\\\tensorflow_checkpoint\\\\model07-cp-{epoch:04d}-ckpt')\n",
    "\n",
    "result = my_model.fit(x_train, \n",
    "                      y_train, \n",
    "                      epochs=500, \n",
    "                      validation_data=(x_test,y_test),\n",
    "                      callbacks=[EarlyStopping(mointor='val_loss',\n",
    "                                               patience=10,\n",
    "                                               verbose=1),\n",
    "                                ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                  patience=3,\n",
    "                                                  factor = 0.5,\n",
    "                                                  min_lr=0.0001,\n",
    "                                                  verbose=1),\n",
    "                                ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1,\n",
    "                                                save_best_only=True)])\n",
    "# 학습 결과\n",
    "result_df = DataFrame(result.history)\n",
    "result_df['epochs']=result_df.index+1\n",
    "result_df.set_index('epochs', inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 학습 결과 평가\n",
    "- 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 그래프 기본설정\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mfont.family\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAppleGothic\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mfont.size\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39maxes.unicode_minus\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 그래프 기본설정\n",
    "plt.rcParams['font.family']='AppleGothic'\n",
    "plt.rcParams['font.size']=12\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "# 그래프를 그리기 위한 객체 생성\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), dpi=150)\n",
    "\n",
    "# 1) 훈련 및 검증 손실 그리기\n",
    "sb.lineplot(x=result_df.index, \n",
    "            y='loss',\n",
    "            data=result_df, \n",
    "            color='blue',\n",
    "            label='훈련 손실률',\n",
    "            ax=ax1)\n",
    "sb.lineplot(x=result_df.index, \n",
    "            y='val_loss',\n",
    "            data=result_df, \n",
    "            color='orange',\n",
    "            label='검증 손실률',\n",
    "            ax=ax1)\n",
    "ax1.set_title('훈련 및 검증 손실률')\n",
    "ax1.set_xlabel('반복회차')\n",
    "ax1.set_ylabel('손실률')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "# 2) 훈련 및 검증 절대오차 그리기\n",
    "sb.lineplot(x=result_df.index,\n",
    "            y='mae',\n",
    "            data=result_df,\n",
    "            color='blue',\n",
    "            label='훈련 절대오차',\n",
    "            ax=ax2)\n",
    "sb.lineplot(x=result_df.index,\n",
    "            y='val_mae',\n",
    "            data=result_df,\n",
    "            color='orange',\n",
    "            label='검증 절대오차',\n",
    "            ax=ax2)\n",
    "ax2.set_title('훈련 및 검증 절대오차')\n",
    "ax2.set_xlabel('반복회차')\n",
    "ax2.set_ylabel('정확도')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> epochs를 500으로 지정했지만 `일찍 학습을 멈춘 것을 확인`할 수 있다\n",
    ">\n",
    "> 즉, 학습을 `조기 종료`함으로서 `학습 성능을 향상`시켰다고 할 수 있다\n",
    "\n",
    "- 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate1 = my_model.evaluate(x_train, y_train)\n",
    "print('최종 훈련 손실률: %f, 최종 훈련 절대오차: %f' % (evaluate1[0], evaluate1[1]))\n",
    "\n",
    "evaluate2 = my_model.evaluate(x_test, y_test)\n",
    "print('최종 검증 손실률: %f, 최종 검증 절대오차: %f' % (evaluate1[0], evaluate2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 학습 결과 적용\n",
    "- 테스트 데이터에 대한 예측 결과 산정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = my_model.predict(x_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf = DataFrame({'검증데이터': x_test.flatten(),\n",
    "                 '실제값': y_test.flatten(),\n",
    "                 '예측값': results.flatten()})\n",
    "\n",
    "kdf['예측오차'] = kdf['실제값'] - kdf['예측값']\n",
    "\n",
    "kdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 결과값과 머신러닝에 의한 예측값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.regplot(x_left=kdf['검증데이터'],\n",
    "               y_left=kdf['실제값'],\n",
    "               y_left_pred=kdf['예측값'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임의의 값에 대한 머신러닝 예측 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 속도가 50일 때의 제동거리를 예측해보자\n",
    "my_speed = 50\n",
    "\n",
    "# 독립변수 표준화에 사용한 객체를 활용\n",
    "my_speed_scale = x_scaler.transform([[my_speed]])\n",
    "my_speed_scale\n",
    "\n",
    "results = my_model.predict(my_speed_scale)\n",
    "results\n",
    "\n",
    "# 예측 결과는 표준화된 값으로 나오기 때문에 원래의 단위로 되돌리기 위해 역변환\n",
    "y_scaler.inverse_transform(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
