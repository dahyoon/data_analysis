데이터분석 자격증 시험:
- https://www.dataq.or.kr/www/sub/a_06.do
- ADP (Advanced Data Professional)
	- 전문가 - 실기 있음
- ADsP (Advanced Data Analytics Semi-Professional)
	- 준전문가 - 실기 없음
	- 코드: R
- 빅데이터분석기사 - 비 추천!!! (너무 어려움 - 수학공식)
	- 현업에서는 인정해 줌

내 컴퓨터에 설치되어있는 파이썬 패키지 목록 조회:
$ pip list
$ pip3 list

데이터 분석 도구:
- R (무료)
- Python (무료)
- SPSS (유료)
- QGIS - 지리정보 분석 (예, 입지 선정)
- GeoDA - 공간회귀 분석 (지역간 연관성)

1. 명령프롬프트 실행
	- WinKey + R -> cmd(엔터)
2. jupyter 설치
	- pip install --upgrade Jupyter      # --upgrade의 의미: 프로그램이 이미 깔려있으면 깔려있는 버전이 최신이 아닐 시 기존의 프로그램을 지우고 최신 버전으로 다운로드
3. jupyter 실행
	- jupyter lab   # 작업 폴더 위치에서 명령프롬프트 

접속 정보 (브라우저 및 os 버전 정보):
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36

vscode setting
- 화면 확대/축소: command + '-' or '+'
- 색상 및 아이콘 테마: extensions에 가서 theme 골라서 적용
- 설정화면 열기: font size

6/19 월 5_카카오책검색:
- 내 애플리케이션 > treehouse(내 앱) > 앱 키 > REST API 키: f903e6bb99d409d576298b6e08527c66
- 문서 > Daum검색 > REST API > 웹문서 검색하기 > GET 의 URL: https://dapi.kakao.com/v2/search/web
- 요청 > 헤더 > Authorization > Authorization: KakaoAK ${REST_API_KEY}
- 인증 방식, 서비스 앱에서 REST API 키로 인증 요청
- 카카오는 "Referer": "" 을 줄 필요 없다; "User-Agent" (웹브라우저 버전 정보)는 옵션
- Meta란 본캐를 설명하는 부가정보
- DataFrame 클래스: 딕셔너리를 포함하는 리스트를 표 형태로 만들어줄 때 씀; 엑셀 시트 같이 생긴 자료구조


6/20 Crawling, HTML, CSS:
- scrapping: 단일 페이지로부터의 데이터 수집
- crawling: 특정 페이지로부터 파생되는 하위 페이지까지 일괄 수집
- crawler: 크롤링을 수행하는 소프트웨어 (=검색엔진)
- html 기본 구성 단축키: html:5 enter
- html은 골격 생성, css는 디자인 구성, javascript는 동작 부여
- markdown: (https://thisblogbusy.tistory.com/entry/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4Markdown-%EC%9D%B4%EB%9E%80)
	- html이 간결화된 글쓰기 도구
	- notion.so: markdown을 간편하게 쓸 수 있도록 만들어진 서비스/웹사이트
	- 태그 종류:
		- 제목 : # =====
		- 인용 : >
		- 강조 : * _ ** __ *** ___
		- 링크 : [텍스트](주소 "설명 생략가능")
		- 이미지 : ![텍스트](이미지주소 "설명 생략가능")
		- 리스트 : 1 * - +
		- 코드표시 : <code>코드</code> , 한줄 띄우고 스페이스 4칸 , ```코드```
		- 줄바꿈 : 엔터 2번 , 강제 줄바꿈은 문장끝에 스페이스바 2칸
		- 가로선 : ----- , ***** , +++++
- 안씨는 영어만 되지만, UTF-8에서는 한글명으로 변수 정의할 수 있음

6/21 Crawling, HTML, CSS:
- url = "https://www.coupang.com/np/search?q=%EB%85%B8%ED%8A%B8%EB%B6%81&listSize=72&channel=user"
	- 통신 방식의 프로토콜 (규약, 규격) - http (일반 웹, 보안x), https (보안 웹)
	- 실제 주소: www.coupang.com/np/search
		- 도메인(컴퓨터 주소): www.coupang.com
		- 파일 경로: /np/search
	- url encoding: q=%EB%85%B8%ED%8A%B8%EB%B6%81&listSize=72&channel=user 
		- ? 뒤에 변수이름=값&변수이름=값
		- 원본 --> 인코딩 --> 형식변환
		- 원본 <-- 디코딩 <-- 변환된 형식
- IP주소: 모든 컴퓨터에 부여되는 인터넷 상의 주소
	- IPv4방식인 숫자 4개로 이루어져있다: xxx.xxx.xxx.xxx 
	- 각 자리는 0-255의 자릿수로 이루어짐
	- 첫 3 자리는 네트워크 상의 그룹주소 (아파트의 동)
	- 마지막 자리는 컴퓨터주소 (아파트의 호)

6/26 Crawling:
- 다운되어있는 pip packages 조회: $ pip list
- selenium:
	- 파이썬, 자바스크립트, 자바, C++ 제공
	- 제어 -> chrome-driver.exe 제어-> chrome browser
	1) 특정 페이지 접속
	2) element 코드 가져오기
	3) 특정 요소(input)에 키보드 입력 보내기
	4) 마우스 클릭 보내기
	5) JS 코드 강제시행 => 스크롤 발생

6/27 SQL:
- 컴퓨터 구조
	1) 대상 컴퓨터의 IP주소를 알면 원격 접속 가능
	2) windows에 docker을 설치한 경우: window에 접속한 port를 docker의 port로 포워딩함
	3) windows에서 해당 port를 열면 (방화벽 해제) 외부에서 나의 docker안에 접속 가능
	4) IP확인

7/3 데이터 시각화:
1. 그래프
	1) 선 - 1갸의 변수, 시간의 흐름 (시계열 그래프)
	2) 막대 - 집단별 집계 결과, 합계, 평균, 빈도
	3) 원 - 집단별 비율, 빈도
	4) 산전도* - x에 따른 y축, 값의 위치
2. 문장 (단어 빈도수)
	- 워드 클라우드
3. 지도 시각화

7/4 데이터 시각화 2:
- 연습문제 2 - 2행1열 그래프 생성, 각각 twix 사용
- %f 는 소수점 6자리까지만 추출

7/13 Mecab:
- 명령 프홈프트 = $ cmd
- 파워쉘 프롬프트 =  $ powershell # 이라고 terminal에 씀
- mac은 add.user.sh <-에 추가 (mecab폴더 안에서 해야 됨))
- mac 에서 mecab이 설치 안 돼서 강사님이 며칠 뒤에 연구해본 후 알려주신다고 하셨음

7/26 주성분분석:
- 종속변수(통제요인)를 판별(넣을지 안 넣을지)할 때 전에 T-Test 검정을 통해 선별함

7/27 주성분분석:
- 명명규칙:
	- 원본 -> df -> 독립변수(x_train)/종속변수(y_train)
	-> 표준화적용 독립변수(x_train_std_df)/종속변수(y_train_std_df)
		- "train"은 '연습한다'라는 뜻
- pca 분석을 사용하여 주성분 분석 시 데이터 표준화 필수
- pca 분석을 안 쓴다면 표준화는 필수가 아니다

8/8 시계열분석:
- Google Colab: 
	- 파이썬 용량이 너무 클 때에는 여기다가 대신 실행 가능
	- 한글(글꼴도) 지원 안함 - linux 명령어를 써서 직접 설치 필요

8/10 선형회귀:
- 회귀형 분석은 보통 카테고리(범주형) 데이터는 숫자로 변환하여 종속변수와
연관성이 있는지 검증한 후 (샤피로, 등등) 한다.
- 회귀 분석은 어떤 독립 변수가(들이) 종속 변수에 가장 영향을 주는지 알아보는 것이 목적
- 샤피로 검정는 데이터(표본)의 수가 50 미만인 경우만 사용한다
- Kolmogorov Smirnov Test은 데이터(표본)의 수가 50 기상인 경우 사용
- PCA 분석은 무조건 표준화 해야 된다
- boxplot을 그릴 경우 data=데이터프레임 으로 주면 알아서 범주형 데이터는 빼고 돌려줌
	- boxplot을 하나씩(컬럼별) 할 경우
- 선형회귀 - 다이아몬드예시.ipynb 마지막에 잔차 분석도 해야 됨
(그런데 시간이 너무 오래 걸려서 수업에서는 안 함)
- ols (ordinary least squares) regression이란?
	- : a method that allows us to find a line that best describes 
	the relationship b/w one or more predictor variables and a 
	response variable.

8/11 금:
- ols 분석 하기 전까지는 분석이 아니라 데이터 전처리이다
- 시간이 오래 걸리는 시각화는 파일 저장해 놓으면 좋음:
	- plt.savefig('파일명.png', dpi= )

getter-setter 설치 방법:
- ctrl + shift 누르면 getter, setter 추가됨 (전에 extension 설치 해서 되어있을 것임)

8/29:
- scikit-learn은 utility의 기능을 습득하는 과정이다
	- from sklearn.impute import `SimpleImputer`
	- from sklearn.model_selection import `train_test_split`
    - from sklearn.preprocessing import `StandardScaler`,`PolynomialFeatures`
	- from sklearn.linear_model import `LinearRegression`
	- from sklearn.metrics import `confusion_matrix`, `roc_curve`, `roc_auc_score`, `accuracy_score`, `recall_score`, `precision_score`, `f1_score`, `r2_score`, `mean_absolute_error`, `mean_squared_error`
- 회귀분석 수행 시 1차를 사용할지 2차를 사용할지 판단하는 기준은 산점도 그래프를 그려봐야 된다 
	- 점들의 배치가 직선/곡선인지 판단 후 사용여부 결정
- 발표 용 파일 저장하기 (산점도 그래프 + 추세선)
	- helper.regplot(... save_path="manhattan_%s.png" % 파일이름)

8/30:
- 사람이 계산하는 통계학이라는 분야에서
	- 통계 라이브러리
		- 통계학 안에서의 특정 연산들을 수행하는 통계 라이브러리들이 있다
		- 용도/전문분야에 따른 각 라이브러리
	- 머신러닝
		- 일반적인 컴퓨팅 프로그래밍으로 만들기 어려운 부분들을 머신러닝이 커버를 해준다
		- 머신러닝은 통계 라이브러리보다 좀 더 넓은 범주를 커버해준다
		- 지도학습, 비지도학습, 강화학습 등등
		- sklearn은 지도와 비지도만 포함한다
		- 강화는 대부분 게임프로그래밍에서 사용한다
	- 그러나 통계라이브러리와 머신러닝의 용도와 기능은 같다.
		- 통계라이브러리와 머신러닝 둘 다 자동화된 기능들이다 (사람이 직접 다 하기 어려운 기능을 제공)
		- 예) ax + b = y 에서 x에 숫자값을 넣는 것은 사람이 할 수 있었으나 그림, 동영상, 자연어 등을 
		대입할 시 사람이 처리를 못하는 경우 발생
		- 통계라이브러리에서도 시간이 너무 오래 걸려 할 수 없음
		- 그러므로 머신러닝 중 지도학습에서 인공신경망이라는 것이 등장
t-값
- t-값의 절대값이 클수록 p-값은 작아지며, 귀무 가설에 대한 증거가 커집니다
- 보통 t-검정은 모집단 평균(2-표본 t) 간 유의한 차이 또는 모집단 평균과 귀무 가설에서의 값(1-표본 t) 간 유의한 차이를 찾기 위해 실시
- t-값은 표본 데이터 변동에 비례한 차이의 크기를 측정
- 다르게 표현하면 T는 계산된 차이를 표준 오차 단위로 나타낸 것으로, 
- T의 크기가 클수록 귀무 가설에 대한 증거가 큼 -> 즉, 유의한 차이가 있다는 증거가 더 명확
- 반면 T가 0에 가까울수록 유의미한 차이가 없을 가능성이 커짐


VIF값
- VIF (Variance Inflation Factor)란, `분산 팽창 인수`라고 합니다
    - 이 값은 다중회귀분석에서 독립변수가 `다중 공산성(Multicollnearity)`의 `문제를 갖고 있는지 판단`하는 기준
	- 주로 `10보다 크면 그 독립변수는 다중공산성이 있다`고 말함

pip command *** 맥은 반드시 pip가 아닌 pip3로 해야 됨
- pip3 install --upgrade package_name
	: installs package_name to the latest version
- pip3 show package_name
	: shows information about package_name
- pip3 list
	: shows lists of existing packages
- python3 -m pip install --upgrade pip
	: pip upgrade

9/13
- 모델의 성능을 어떻게 향상시켰는가 - 인터뷰 때 포커스를 맞춰야 함

9/14
- visual studio에서 변수값들 확인: Variables(+Code 버튼 있는 상단 맨 오른쪽에 있음)