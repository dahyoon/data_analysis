데이터분석 자격증 시험:
- https://www.dataq.or.kr/www/sub/a_06.do
- ADP (Advanced Data Professional)
	- 전문가 - 실기 있음
- ADsP (Advanced Data Analytics Semi-Professional)
	- 준전문가 - 실기 없음
	- 코드: R
- 빅데이터분석기사 - 비 추천!!! (너무 어려움 - 수학공식)
	- 현업에서는 인정해 줌

내 컴퓨터에 설치되어있는 파이썬 패키지 목록 조회:
$ pip list
$ pip3 list

데이터 분석 도구:
- R (무료)
- Python (무료)
- SPSS (유료)
- QGIS - 지리정보 분석 (예, 입지 선정)
- GeoDA - 공간회귀 분석 (지역간 연관성)

1. 명령프롬프트 실행
	- WinKey + R -> cmd(엔터)
2. jupyter 설치
	- pip install --upgrade Jupyter      # --upgrade의 의미: 프로그램이 이미 깔려있으면 깔려있는 버전이 최신이 아닐 시 기존의 프로그램을 지우고 최신 버전으로 다운로드
3. jupyter 실행
	- jupyter lab   # 작업 폴더 위치에서 명령프롬프트 

접속 정보 (브라우저 및 os 버전 정보):
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36

vscode setting
- 화면 확대/축소: command + '-' or '+'
- 색상 및 아이콘 테마: extensions에 가서 theme 골라서 적용
- 설정화면 열기: font size

6/19 월 5_카카오책검색:
- 내 애플리케이션 > treehouse(내 앱) > 앱 키 > REST API 키: f903e6bb99d409d576298b6e08527c66
- 문서 > Daum검색 > REST API > 웹문서 검색하기 > GET 의 URL: https://dapi.kakao.com/v2/search/web
- 요청 > 헤더 > Authorization > Authorization: KakaoAK ${REST_API_KEY}
- 인증 방식, 서비스 앱에서 REST API 키로 인증 요청
- 카카오는 "Referer": "" 을 줄 필요 없다; "User-Agent" (웹브라우저 버전 정보)는 옵션
- Meta란 본캐를 설명하는 부가정보
- DataFrame 클래스: 딕셔너리를 포함하는 리스트를 표 형태로 만들어줄 때 씀; 엑셀 시트 같이 생긴 자료구조


6/20 Crawling, HTML, CSS:
- scrapping: 단일 페이지로부터의 데이터 수집
- crawling: 특정 페이지로부터 파생되는 하위 페이지까지 일괄 수집
- crawler: 크롤링을 수행하는 소프트웨어 (=검색엔진)
- html 기본 구성 단축키: html:5 enter
- html은 골격 생성, css는 디자인 구성, javascript는 동작 부여
- markdown: (https://thisblogbusy.tistory.com/entry/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4Markdown-%EC%9D%B4%EB%9E%80)
	- html이 간결화된 글쓰기 도구
	- notion.so: markdown을 간편하게 쓸 수 있도록 만들어진 서비스/웹사이트
	- 태그 종류:
		- 제목 : # =====
		- 인용 : >
		- 강조 : * _ ** __ *** ___
		- 링크 : [텍스트](주소 "설명 생략가능")
		- 이미지 : ![텍스트](이미지주소 "설명 생략가능")
		- 리스트 : 1 * - +
		- 코드표시 : <code>코드</code> , 한줄 띄우고 스페이스 4칸 , ```코드```
		- 줄바꿈 : 엔터 2번 , 강제 줄바꿈은 문장끝에 스페이스바 2칸
		- 가로선 : ----- , ***** , +++++
- 안씨는 영어만 되지만, UTF-8에서는 한글명으로 변수 정의할 수 있음

6/21 Crawling, HTML, CSS:
- url = "https://www.coupang.com/np/search?q=%EB%85%B8%ED%8A%B8%EB%B6%81&listSize=72&channel=user"
	- 통신 방식의 프로토콜 (규약, 규격) - http (일반 웹, 보안x), https (보안 웹)
	- 실제 주소: www.coupang.com/np/search
		- 도메인(컴퓨터 주소): www.coupang.com
		- 파일 경로: /np/search
	- url encoding: q=%EB%85%B8%ED%8A%B8%EB%B6%81&listSize=72&channel=user 
		- ? 뒤에 변수이름=값&변수이름=값
		- 원본 --> 인코딩 --> 형식변환
		- 원본 <-- 디코딩 <-- 변환된 형식
- IP주소: 모든 컴퓨터에 부여되는 인터넷 상의 주소
	- IPv4방식인 숫자 4개로 이루어져있다: xxx.xxx.xxx.xxx 
	- 각 자리는 0-255의 자릿수로 이루어짐
	- 첫 3 자리는 네트워크 상의 그룹주소 (아파트의 동)
	- 마지막 자리는 컴퓨터주소 (아파트의 호)

6/26 Crawling:
- 다운되어있는 pip packages 조회: $ pip list
- selenium:
	- 파이썬, 자바스크립트, 자바, C++ 제공
	- 제어 -> chrome-driver.exe 제어-> chrome browser
	1) 특정 페이지 접속
	2) element 코드 가져오기
	3) 특정 요소(input)에 키보드 입력 보내기
	4) 마우스 클릭 보내기
	5) JS 코드 강제시행 => 스크롤 발생

6/27 SQL:
- 컴퓨터 구조
	1) 대상 컴퓨터의 IP주소를 알면 원격 접속 가능
	2) windows에 docker을 설치한 경우: window에 접속한 port를 docker의 port로 포워딩함
	3) windows에서 해당 port를 열면 (방화벽 해제) 외부에서 나의 docker안에 접속 가능
	4) IP확인

7/3 데이터 시각화:
1. 그래프
	1) 선 - 1갸의 변수, 시간의 흐름 (시계열 그래프)
	2) 막대 - 집단별 집계 결과, 합계, 평균, 빈도
	3) 원 - 집단별 비율, 빈도
	4) 산전도* - x에 따른 y축, 값의 위치
2. 문장 (단어 빈도수)
	- 워드 클라우드
3. 지도 시각화

7/4 데이터 시각화 2:
- 연습문제 2 - 2행1열 그래프 생성, 각각 twix 사용
- %f 는 소수점 6자리까지만 추출

7/13 Mecab:
- 명령 프홈프트 = $ cmd
- 파워쉘 프롬프트 =  $ powershell # 이라고 terminal에 씀
- mac은 add.user.sh <-에 추가 (mecab폴더 안에서 해야 됨))
- mac 에서 mecab이 설치 안 돼서 강사님이 며칠 뒤에 연구해본 후 알려주신다고 하셨음