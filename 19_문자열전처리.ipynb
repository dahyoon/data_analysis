{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbNjCZlBh3vlp+TKoeSgNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lolddong/data_analysis/blob/main/19_%EB%AC%B8%EC%9E%90%EC%97%B4%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문자열 데이터 전처리\n",
        "\n",
        "## 1. Colab에 Mecab-kor-doc 설치하기\n",
        "- 한글 형태소 분석을 수행할 경우 새로운 노트북 생성시마다 해줘야 한다.\n"
      ],
      "metadata": {
        "id": "l2D76OkPIr4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "!bash Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab_light_220429.sh"
      ],
      "metadata": {
        "id": "rE_fn-HVT06K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d94ae12-a522-462b-f5cb-fc206ed5e34d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (138/138), 1.72 MiB | 25.45 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-10-03 16:19:12--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNM634LST5&Signature=5rdxgxYWSzb4LITtgp%2FqiiLwBKY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjECkaCXVzLWVhc3QtMSJIMEYCIQCBZVzq8rhZdUdVLK9i1rCaLOyZd55uKMjwSaqiVwTuGAIhAKoLFt7SKRCShc3uyhA046pu8QyWiEKvESU6w8vukYAIKqcCCDEQABoMOTg0NTI1MTAxMTQ2IgwhgR61yvPEjhy%2BjjgqhAJEgNFz2OhvePg2U1lHYI6QbkQW19RqdtnWTlYZtY20c5cTNDQ8JkC5gRavn3uhOk8bOomBAhugaEDfJIW596UHd32G7SlWE50iqYO8CTWy0ySMyZejv2J2mENbIObvl4wTvtz9FPMC80doY27EjtuUxGbNWrhuyoKg6%2BKI3QPC8l1hTaTqUWO3XeLvJ8VAnhTqn%2B2GrWPIsvwdBSxok50%2BemhV0iT9HYjK6w632oByGmWHtIu1Jy162XU%2BWhsqkISS66gehvsyOXb%2Fz2I7p8SOx5KuB%2BZ85dWXL8qGbRPIUZLS%2BrAlrrLy1gPX3l%2FYgkRbXHojGZNyiFnhHYE6ej0xS%2Fj0TDDA%2FfCoBjqcAREzLHa4BDKTU%2F6XemKk8Qmz26PB%2FqtO9ClnM%2FYkV0ChGG85d9NfIdc760zcBjdaLFBcWX2P9sHnmMShS2tOekfxBOjDPj5%2FnCFfCyn21YBuPC5dZQaexKRDeDNIzB3nSpK%2F0w0PKNRV4TSDGi5uqhG6XM3k7lsnmzcrI1lbJaezdiyk32AYjMqwRCC0nwcdgD2A1DeE5g%2BUaqwI5A%3D%3D&Expires=1696351688 [following]\n",
            "--2023-10-03 16:19:12--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNM634LST5&Signature=5rdxgxYWSzb4LITtgp%2FqiiLwBKY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjECkaCXVzLWVhc3QtMSJIMEYCIQCBZVzq8rhZdUdVLK9i1rCaLOyZd55uKMjwSaqiVwTuGAIhAKoLFt7SKRCShc3uyhA046pu8QyWiEKvESU6w8vukYAIKqcCCDEQABoMOTg0NTI1MTAxMTQ2IgwhgR61yvPEjhy%2BjjgqhAJEgNFz2OhvePg2U1lHYI6QbkQW19RqdtnWTlYZtY20c5cTNDQ8JkC5gRavn3uhOk8bOomBAhugaEDfJIW596UHd32G7SlWE50iqYO8CTWy0ySMyZejv2J2mENbIObvl4wTvtz9FPMC80doY27EjtuUxGbNWrhuyoKg6%2BKI3QPC8l1hTaTqUWO3XeLvJ8VAnhTqn%2B2GrWPIsvwdBSxok50%2BemhV0iT9HYjK6w632oByGmWHtIu1Jy162XU%2BWhsqkISS66gehvsyOXb%2Fz2I7p8SOx5KuB%2BZ85dWXL8qGbRPIUZLS%2BrAlrrLy1gPX3l%2FYgkRbXHojGZNyiFnhHYE6ej0xS%2Fj0TDDA%2FfCoBjqcAREzLHa4BDKTU%2F6XemKk8Qmz26PB%2FqtO9ClnM%2FYkV0ChGG85d9NfIdc760zcBjdaLFBcWX2P9sHnmMShS2tOekfxBOjDPj5%2FnCFfCyn21YBuPC5dZQaexKRDeDNIzB3nSpK%2F0w0PKNRV4TSDGi5uqhG6XM3k7lsnmzcrI1lbJaezdiyk32AYjMqwRCC0nwcdgD2A1DeE5g%2BUaqwI5A%3D%3D&Expires=1696351688\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.118.121, 3.5.25.231, 52.216.61.217, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.118.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.96MB/s    in 0.5s    \n",
            "\n",
            "2023-10-03 16:19:13 (2.96 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-10-03 16:20:47--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNL6G2IPWN&Signature=n8afzcfmvU21V7UudjghFh6zT1Q%3D&x-amz-security-token=IQoJb3JpZ2luX2VjECkaCXVzLWVhc3QtMSJIMEYCIQCb6gYbDuKSfMnlkTCevl2PNM1DwbyaGyOF3hmbofinIgIhAK5MyJk4x8Eq7vEbE%2FCA8uW3mpD7nDBv4LErHMZCmrwHKqcCCDEQABoMOTg0NTI1MTAxMTQ2Igzf2OYsqYCaUSjvSzMqhALhQgtsKwMF%2FSqRjvZqnvz7I5ad3OWtOEDm96NP5SHUuaTlspE2scT25qnUtyslfJE8WLDPWqzuZzo1CcomsGM7aR0EJUsquYB%2FnNFLQe9xdl2wfNm073gqspusas5m0Z6qlQUYCsimE6V8y3kFvXe78va2KdFb5x1tZerp3ex8qqTDRSpHjTeieRu9rCPNwsnMvmL%2FxfRVcd1laAD94KBPCvivXQaP8o4%2F4kknEKqWkTFT5Xtmr1jYyp2d5aTJCWaZQ00WNFCsp%2BFRj9xAsgMNFglo97Fsb5xIWzZZ6i2issRTXz6rEKnUQ3IrD336%2FmTC5j0Pp9EIgL6l020p6RTfDcXazjDM%2FvCoBjqcARd3mghdJeJqY2gB%2Fb3n9l4vUz9QpjfO8f2MMIVeX4jMsLTHanOxNkENr9lhmLrFQMMvUaQQuFrdc51g4KjUkc0ZsZVVYgAZPDgrNB%2BG6a%2FmrCgML7KGkJX94wjw8XETYmMbsf0tOnnMUESQqjbk03jjG0MsYfv3trHSQxvnb06VoXNcTuSF8BJ8O8WrsyXMNF47BjM3Loy2LvdltQ%3D%3D&Expires=1696351828 [following]\n",
            "--2023-10-03 16:20:48--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNL6G2IPWN&Signature=n8afzcfmvU21V7UudjghFh6zT1Q%3D&x-amz-security-token=IQoJb3JpZ2luX2VjECkaCXVzLWVhc3QtMSJIMEYCIQCb6gYbDuKSfMnlkTCevl2PNM1DwbyaGyOF3hmbofinIgIhAK5MyJk4x8Eq7vEbE%2FCA8uW3mpD7nDBv4LErHMZCmrwHKqcCCDEQABoMOTg0NTI1MTAxMTQ2Igzf2OYsqYCaUSjvSzMqhALhQgtsKwMF%2FSqRjvZqnvz7I5ad3OWtOEDm96NP5SHUuaTlspE2scT25qnUtyslfJE8WLDPWqzuZzo1CcomsGM7aR0EJUsquYB%2FnNFLQe9xdl2wfNm073gqspusas5m0Z6qlQUYCsimE6V8y3kFvXe78va2KdFb5x1tZerp3ex8qqTDRSpHjTeieRu9rCPNwsnMvmL%2FxfRVcd1laAD94KBPCvivXQaP8o4%2F4kknEKqWkTFT5Xtmr1jYyp2d5aTJCWaZQ00WNFCsp%2BFRj9xAsgMNFglo97Fsb5xIWzZZ6i2issRTXz6rEKnUQ3IrD336%2FmTC5j0Pp9EIgL6l020p6RTfDcXazjDM%2FvCoBjqcARd3mghdJeJqY2gB%2Fb3n9l4vUz9QpjfO8f2MMIVeX4jMsLTHanOxNkENr9lhmLrFQMMvUaQQuFrdc51g4KjUkc0ZsZVVYgAZPDgrNB%2BG6a%2FmrCgML7KGkJX94wjw8XETYmMbsf0tOnnMUESQqjbk03jjG0MsYfv3trHSQxvnb06VoXNcTuSF8BJ8O8WrsyXMNF47BjM3Loy2LvdltQ%3D%3D&Expires=1696351828\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.161.41, 52.217.225.121, 52.217.136.161, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.161.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  35.9MB/s    in 1.3s    \n",
            "\n",
            "2023-10-03 16:20:49 (35.9 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 패키지 참조"
      ],
      "metadata": {
        "id": "xIIaA-4dUMm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "vVUjJr-RX1aP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 문자열 토큰화\n",
        "- 학습 데이터에서 `단어` 단위로 일련번호로 변환하는 처리\n",
        "### 1) Token (=형태소)\n",
        "- 문법적으로 더 이상 나눌 수 없는 언어 요소\n",
        "- 영어의 경우 각 단어로 나누면 되지만 한글의 경우 복잡한 처리 과정을 거쳐야 하기 때문에 별도의 라이브러리를 적용해야 한다 (konlpy, mecab 등)\n",
        "### 2) 영어 문장에 대한 토큰화\n",
        "#### 토큰화 학습 데이터\n",
        "- 리스트 안에 문자열들을 줌"
      ],
      "metadata": {
        "id": "WhS1I8upUUkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = ['You are the Best', 'You are the Nice']"
      ],
      "metadata": {
        "id": "Aak61kgMUz5h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 토큰화 객체 생성\n",
        "- `Tokenizer(num_words = n, oov_token = '<OOV>')`\n",
        "  - `num_words`: 밀집 표현의 최대 백터 길이를 지정 (= 최대 단어 수)\n",
        "  - `oov_token`: 학습 결과를 적용할 떄 학습 데이터에 포함되지 않은 단어가 존재할 경우 대체할 단어"
      ],
      "metadata": {
        "id": "89W-gK4bU4tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 10, oov_token = '<OOV>')"
      ],
      "metadata": {
        "id": "lnb2jEsWVOKb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 토큰화 학습하기/수행\n",
        "- `토큰화객체.fit_on_texts(토큰화학습데이터)`"
      ],
      "metadata": {
        "id": "CxkA13egVg2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 학습\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "# 각 단어에 부여된 인덱스 번호 확인\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "q2gx_PZzVgOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f808f7-963a-4254-94c0-e879a991db58"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'you': 2, 'are': 3, 'the': 4, 'best': 5, 'nice': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습 결과 적용하기\n",
        "- 토큰화를 학습한 모델에 새로운 단어를 적용하여 밀집 백터로 변환한다"
      ],
      "metadata": {
        "id": "-dR8qS9xWdeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'We'라는 단어 추가\n",
        "train_text2 = ['We are the Best', 'We are the Nice']\n",
        "sequences = tokenizer.texts_to_sequences(train_text2)\n",
        "print(sequences)"
      ],
      "metadata": {
        "id": "7HG4onmzWowF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd4bbe5-5c22-45c2-efd0-51d47c46c8d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 3, 4, 5], [1, 3, 4, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) 한글 문장 토큰화\n",
        "- 형태소 분석 엔진 `Mecab`을 설치해야 한다\n",
        "#### 토큰화 학습 데이터"
      ],
      "metadata": {
        "id": "UMhDuuCEV-P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem = '''\n",
        "흘러내린 머리카락이 흐린 호박빛 아래 빛난다.\n",
        "난 유영한다. 차분하게 과거에 살면서 현재의 공기를 마신다.\n",
        "가로등이 깜빡인다.\n",
        "나도 깜빡여준다.\n",
        "'''"
      ],
      "metadata": {
        "id": "_QRYxozAWI_X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 불용어(stopwords) 목록\n",
        "- 분석에서 제외할 불필요한 단어에 대한 목록\n",
        "- 개발자가 임의로 정하거나 불용어 사전을 웹에서 내려받아 사용할 수 있다"
      ],
      "metadata": {
        "id": "HWyPibj5WOer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['난', '나']"
      ],
      "metadata": {
        "id": "nRj4Dl_TXKfY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 형태소 분석을 통해 명사만 추출하기"
      ],
      "metadata": {
        "id": "FmnUwDdBXPEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mecab = Mecab()\n",
        "nouns = mecab.nouns(poem)\n",
        "print(nouns)"
      ],
      "metadata": {
        "id": "Jgdqv99kXO3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c20bade-2c65-469a-8659-d233b8f73dab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['머리카락', '호박', '빛', '아래', '난', '유영', '과거', '현재', '공기', '가로등', '나']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 추출된 명사에서 불용어를 제외한 새로운 리스트 만들기"
      ],
      "metadata": {
        "id": "bjGtUWkFXYjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_filtered = []\n",
        "for i in nouns:\n",
        "  if i not in stopwords:\n",
        "    train_text_filtered.append(i)\n",
        "train_text_filtered"
      ],
      "metadata": {
        "id": "_B0qhSVAXdSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bafb5a2-9410-40d8-a4d4-6e9d98090f88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['머리카락', '호박', '빛', '아래', '유영', '과거', '현재', '공기', '가로등']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 토큰화 학습하기/수행\n",
        "- `토큰화객체.fit_on_texts(토큰화학습데이터)`"
      ],
      "metadata": {
        "id": "VIOqLcU2XqPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = len(nouns),\n",
        "                      oov_token = '<OOV>')\n",
        "tokenizer.fit_on_texts(train_text_filtered)\n",
        "print(tokenizer.word_index) # 인덱스 번호 확인"
      ],
      "metadata": {
        "id": "K1XYi3qcXr1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464255f3-a4d0-47dd-f602-2a465e68a250"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, '머리카락': 2, '호박': 3, '빛': 4, '아래': 5, '유영': 6, '과거': 7, '현재': 8, '공기': 9, '가로등': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 워드 임베딩 (Word Embedding)\n",
        "- 컴퓨터가 자연어를 이해하고 효율적으로 처리하게 하기 위해서는 컴퓨터가 이해할 수 있도록 자연어를 적절히 변환할 필요가 있다\n",
        "- 워드 임베딩(Word Embedding)은 단어를 `백터`로 표현하는 방법으로, 단어를 희소표현이 개선된 형태인 `밀집표현`으로 변환한다\n",
        "\n",
        "### 1) 희소 표현 (원-핫 백터 One-Hot Vector)\n",
        "- 원-핫 인코딩과 비슷한 방법\n",
        "- 표현하고자 하는 단어의 인덱스 값만 1이고 나머지 인덱스에는 전부 0으로 표현되는 백터 방법으로 `원-핫 백터`라고도 한다\n",
        "\n",
        "#### 예시 문장 2개\n",
        "- '머신러닝 공부는 재미있다.'\n",
        "- '머신러닝은 유용하다.'\n",
        "\n",
        "#### 형태소 분석\n",
        "- 위의 두 예문에서 명사인 단어만 추출한다면 다음과 같다.\n",
        "  - '머신러닝', '공부', '재미'\n",
        "  - '머신러닝', '유용'\n",
        "\n",
        "#### 토큰화\n",
        "- 각 단어에 인덱스 번호를 적용한다면 아래와 같이 표현할 수 있을 것이다\n",
        "  - 0, 1, 2\n",
        "  - 0, 3\n",
        "\n",
        "#### 희소표현\n",
        "- 전체 단어의 수가 `4`개이므로 각각의 단어를 4개의 원소를 갖는 리스트 안에서 one-hot encoding으로 표현한다\n",
        "  - [ [1,0,0,0], [0,1,0,0], [0,0,1,0] ]\n",
        "  - [ [1,0,0,0], [0,0,0,1] ]\n",
        "\n",
        "#### 희소표현의 한계\n",
        "- 단어의 개수가 늘어나면 백터의 차원이 한없이 커진다\n",
        "- 여러 문장을 통해 얻어진 단어가 10,000개이고 그 중에서 5개의 단어로 구성된 문장이라면 백터의 총 길이는 50,000이 된다\n",
        "- 그러므로 공간적인 낭비를 가져온다\n",
        "\n",
        "### 2) 밀집 표현\n",
        "- 희소 표현의 반대\n",
        "- 백터의 차원을 단어 집합의 크기로 결정하지 않고 분석가가 설정한 임의의 값으로 모든 단어 백터의 차원을 맞춘다\n",
        "- `0`과 `1`이 아닌 `실수`를 원소로 갖는다\n",
        "\n",
        "#### 예시\n",
        "- (앞서 제시한 예시 문장에서 `머신러닝`이라는 단어의 예시)\n",
        "- 희소 표현 → [1,0,0,0]\n",
        "- 백터의 차원을 2로 설정한 밀집표현 → [1.8, -0.4]\n",
        "> 수치 값은 임의의 값이다. 이와 같은 식으로 실수 형태로 표현된다는 것을 표현한 것일 뿐 실제 정확한 값은 아님을 이해하자\n",
        "- 결과적으로 백터의 차원이 조밀해졌다고 하여 밀집 백터라 부른다\n",
        "\n",
        "### 3) 워드 임베딩 Word Embedding\n",
        "- 단어를 밀집 백터의 형태로 표현한 방법\n",
        "- 케라스에서는 `토큰화` 한 단어 백터를 `Embedding()` 함수에 전달하여 학습층을 쌓음으로서 적용할 수 있다.\n",
        "- 단어를 랜덤한 값을 갖는 밀집 백터로 변환한 뒤, 인공 신경망의 가중치를 학습하는 방식으로 단어 백터를 학습한다"
      ],
      "metadata": {
        "id": "4KXNZfQyYcRh"
      }
    }
  ]
}