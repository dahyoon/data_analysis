{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqid0mOS84LkTZyU/XLSK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lolddong/data_analysis/blob/main/21_IMDB_RNN(not_run).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB RNN\n",
        "\n",
        "## 0. 텍스트 분석 알고리즘\n",
        "### 1) 텍스트 분석을 위해 개선된 알고리즘의 종류\n",
        "#### RNN\n",
        "- Embedding 층은 단순하게 데이터의 표현을 학습하여 데이터 사전을 구축하는 것\n",
        "- 유사한 의미의 단어를 비슷한 공간에 매핑할 수 있지만, 시퀀스 데이터의 중요한 특성인 순서와 맥락까지 고려한 것은 아니다\n",
        "- 순환 신경망은 이 문제를 해결하기 위해 고안된 층\n",
        "- 완전연결층, 컨볼루션 신경망과 반대되는 개념\n",
        "- 완전연결층과 컨볼루션 신경망은 피드 포워드 네트워크(feed-forward network)라고 표현\n",
        "- `피드 포워드 네트워크`는 신경망이 가지는 `모든 출력값`이 마지막층인 `출력층을 향한다`\n",
        "- 하지만 `순환 신경망`은 각 층의 결과값이 출력층을 향하면서도 동시에 `현재 층의 다음 계산에 사용`된다\n",
        "\n",
        "#### LSTM\n",
        "- RNN의 그래디언트 손실문제를 보완한 방법\n",
        "- 정보를 여러 시점에 걸쳐 나르는 장치('Cell State')가 추가되었다\n",
        "- 이로 인해 그래디언트를 보존할 수 있어 그래디언트 손실 문제가 발생하지 않도록 도와준다\n",
        "\n",
        "#### GRN\n",
        "- 게이트 메커니즘이 적용된 RNN의 일종으로 LSTM에서 영감을 받았으며 더 간략한 구조를 갖는다\n",
        "- 한국인 조경현 박사님이 제안한 방법\n",
        "\n",
        "### 2) 텍스트 분석 알고리즘 적용하기\n",
        "- 전체 소스코드는 지금까지의 예제들과 동일하게 진행된다\n",
        "> 1. 패키지 준비 → 2. 데이터셋 준비 → 3. 데이터 전처리 → 4. 탐색적 데이터 분석(문자열 토큰화, 데이터를 동일한 길이로 맞추기) → 5. 데이터 셋 분할 → 6. 모델 개발(정의+학습) → 7. 학습 결과 평가 → 8. 학습결과 적용\n",
        "\n",
        "- 이 과정에서 학습 모델을 정의하는 부분에서 적용할 알고리즘만 변경하면 되기에 여기서는 RNN을 먼저 적용해 본 후, 학습 모델을 LSTM과 GRU로 각각변경하여 다시 학습을 수행해 보도록 한다\n",
        "- 학습 시간이 매우 오래 걸리는 예제이므로 가급적 GPU가 탑재된 컴퓨터에서 실습하는 것이 좋다\n",
        "\n",
        "## 1. 패키지 준비하기"
      ],
      "metadata": {
        "id": "l2D76OkPIr4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import helper\n",
        "from matplotlib import pyplot as plt\n",
        "from pandas import DataFrame\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "form sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "KrwPWCqk7TLs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터셋 준비"
      ],
      "metadata": {
        "id": "tbIwNqy973HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 빈번하게 사용되는 단어의 갯수\n",
        "num_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "print(f'훈련 데이터 {x_train.shape} 레이블 {y_train.shape}')\n",
        "print(f'검증 데이터 {x_test.shape} 레이블 {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM3-pHF574uo",
        "outputId": "199c4116-13b1-4741-def8-88647106adc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "훈련 데이터 (25000,) 레이블 (25000,)\n",
            "검증 데이터 (25000,) 레이블 (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터 전처리\n",
        "### 1) 데이터를 동일한 길이로 맞추기 (padding)"
      ],
      "metadata": {
        "id": "27rR7up_8Qfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 문장 길이\n",
        "max_len = 500\n",
        "print('Before pad_sequences: ', len(x_train[0]), len(x_train[1]))\n",
        "pad_x_train = pad_sequences(x_train, maxlen=max_len, padding='pre')\n",
        "pad_x_test =  pad_sequences(x_test, maxlen=max_len, padding='pre')\n",
        "\n",
        "# 원래 단어의 앞에 '지정해준 단어의 길이 - 원해 단어의 길이' (500-218)만큼 0이 추가된 것을 볼 수 있다\n",
        "print('After pad_sequences: ', len(pad_x_train[0]), len(pad_x_train[1]))\n",
        "\n",
        "print(pad_x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ayLNKoJ8QUs",
        "outputId": "4335a1a5-f3f1-4c52-daaa-093b438d2fc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before pad_sequences:  218 189\n",
            "After pad_sequences:  500 500\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    1   14   22   16   43  530  973 1622 1385   65  458 4468\n",
            "   66 3941    4  173   36  256    5   25  100   43  838  112   50  670\n",
            "    2    9   35  480  284    5  150    4  172  112  167    2  336  385\n",
            "   39    4  172 4536 1111   17  546   38   13  447    4  192   50   16\n",
            "    6  147 2025   19   14   22    4 1920 4613  469    4   22   71   87\n",
            "   12   16   43  530   38   76   15   13 1247    4   22   17  515   17\n",
            "   12   16  626   18    2    5   62  386   12    8  316    8  106    5\n",
            "    4 2223 5244   16  480   66 3785   33    4  130   12   16   38  619\n",
            "    5   25  124   51   36  135   48   25 1415   33    6   22   12  215\n",
            "   28   77   52    5   14  407   16   82    2    8    4  107  117 5952\n",
            "   15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
            "  400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
            "   98   32 2071   56   26  141    6  194 7486   18    4  226   22   21\n",
            "  134  476   26  480    5  144   30 5535   18   51   36   28  224   92\n",
            "   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
            " 4472  113  103   32   15   16 5345   19  178   32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 데이터셋 분할하기\n",
        "- 이미 데이터셋이 훈련데이터와 검증데이터로 분리되어 있기 때문에 별도의 분할 작업을 수행할 필요는 없다."
      ],
      "metadata": {
        "id": "m2Idf4r29Tx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 모델 개발\n",
        "### 1) 모델 정의 (RNN)\n",
        "  - 파라미터:\n",
        "    - `return_sequences`:\n",
        "      - True ->  모든 학습 시점의 은닉상태를 출력해줌\n",
        "      - False -> 마지막 시점의 은닉 상태만 출력 - default는 False\n",
        "    - dropout:\n",
        "      - 지정된 비율만큼 학습을 건너뛰게 하는 파라미터\n",
        "      - 이 파라미터를 사용하면 과거 학습 정보를 잃어버릴 확률이 높아지고 그에 따라 모델 성능이 나빠질 가능성이 있다\n",
        "    - recurrent_dropout(순환드롭아웃):\n",
        "      - 과거 학습정보를 잃어버리는 문제를 해결하기 위해 적용하는 옵션"
      ],
      "metadata": {
        "id": "sS6gS3_g9Y7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = Sequential()\n",
        "my_model.add(Embedding(input_dim = num_words,\n",
        "                       output_dim = 32,\n",
        "                       input_length = max_len))\n",
        "my_model.add(SimpleRNN(32,\n",
        "                       return_sequences=True,\n",
        "                       dropout=0.15,\n",
        "                       recurrent_dropout=0.15))\n",
        "my_model.add(SimpleRNN(16))\n",
        "my_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 결국은 긍정, 부정을 분류하는 문제이므로 이진분류에 해당한다\n",
        "my_model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['acc'])\n",
        "my_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjb7Soqh8PZq",
        "outputId": "e0cbe8eb-8b4e-4941-c9b8-948ccd12e39c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 500, 32)           2080      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 16)                784       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322881 (1.23 MB)\n",
            "Trainable params: 322881 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 학습하기"
      ],
      "metadata": {
        "id": "LQ-WSAdc_Bxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = my_model.fit(pad_x_train,\n",
        "                      y_train,\n",
        "                      epochs=500,\n",
        "                      validation_data=(pad_x_test, y_test),\n",
        "                      callbacks=[EarlyStopping(monitor='val_loss',\n",
        "                                               patience=5,\n",
        "                                               verbose=1),\n",
        "                                 ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                   patience=3,\n",
        "                                                   factor=0.5,\n",
        "                                                   min_lr=0.0001,\n",
        "                                                   verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "jUzQa-8X89Zh",
        "outputId": "ac96adf3-ed5a-40f3-d5d4-1c43b25dfc10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "782/782 [==============================] - 1117s 1s/step - loss: 0.6837 - acc: 0.5543 - val_loss: 0.6669 - val_acc: 0.6235 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "  9/782 [..............................] - ETA: 15:48 - loss: 0.6788 - acc: 0.5486"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fbfdda6b25ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result = my_model.fit(pad_x_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_x_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       callbacks=[EarlyStopping(monitor='val_loss',\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 학습결과 평가"
      ],
      "metadata": {
        "id": "AGwU2-LcAKNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 강사님 helper 코드\n",
        "# helper.tf_result_plot(result)\n",
        "\n",
        "# evaluate1 = my_model.evaluate(pad_x_train, y_train)\n",
        "# print('최종 훈련 손실률: %f, 최종 훈련 정확도: %f' % (evaluate1[0], evaluate1[1]))\n",
        "# evaluate2 = my_model.evaluare(pad_x_test, y_test)\n",
        "# print('최종 검증 손슬률: %f, 최종 검증 정확도: %f' % (evaluate2[0], evaluate2[1]))"
      ],
      "metadata": {
        "id": "_z57QU1L_g26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과\n",
        "result_df = DataFrame(result.history)\n",
        "result_df['epochs'] = result_df.index+1\n",
        "result_df.set_index('epochs', inplace = True)\n",
        "result_df"
      ],
      "metadata": {
        "id": "2vvbOBKFAaW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 그래프 한글글꼴 설정\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm-/.cache/matplotlib -rf\n",
        "\n",
        "from matplotlib import font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "fe = fm.FontEntry(fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
        "                  name='NanumGothic')\n",
        "fm.fontManager.ttflist.insert(0, fe)\n",
        "plt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'})"
      ],
      "metadata": {
        "id": "LSVj4a7SAb_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 기본설정\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 그래프를 그리기 위한 객체 생성\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5), dpi=150)\n",
        "\n",
        "# 1) 훈련 및 검증 손실 그리기\n",
        "sb.lineplot(x=result_df.index,\n",
        "            y='loss',\n",
        "            data=result_df,\n",
        "            color='lightblue',\n",
        "            label='훈련 손실률',\n",
        "            ax=ax1)\n",
        "sb.lineplot(x=result_df.index,\n",
        "            y='val_loss',\n",
        "            data=result_df,\n",
        "            color='lightcoral',\n",
        "            label='검증 손실률',\n",
        "            ax = ax1)\n",
        "ax1.set_title('훈련 및 검증 손실률')\n",
        "ax1.set_xlabel('반복회차')\n",
        "ax1.set_ylabel('손실률')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "# 2) 훈련 및 검증 정확도 그리기\n",
        "sb.lineplot(x=result_df.index,\n",
        "            y='acc',\n",
        "            data=result_df,\n",
        "            color='lightblue',\n",
        "            label='훈련 정확도',\n",
        "            ax=ax2)\n",
        "sb.lineplot(x=result_df.index,\n",
        "            y='val_acc',\n",
        "            data=result_df,\n",
        "            color='lightcoral',\n",
        "            label='검증 정확도',\n",
        "            ax=ax2)\n",
        "ax2.set_title('훈련 및 검증 정확도')\n",
        "ax2.set_xlabel('반복회차')\n",
        "ax2.set_ylabel('정확도')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "MUNnx5IyAdjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate1 = my_model.evaluate(pad_x_train, y_train)\n",
        "print('최종 훈련 손실률: %f, 최종 훈련 정확도: %f' % (evaluate1[0], evaluate1[1]))\n",
        "evaluate2 = my_model.evaluate(pad_x_test, y_test)\n",
        "print('최종 검증 손실률: %f, 최종 검증 정확도: %f' % (evaluate2[0], evaluate2[1]))"
      ],
      "metadata": {
        "id": "s12zuZ8WA-RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 학습 결과 적용\n",
        "### 1) 훈련 데이터에 대한 예측 결과 산정"
      ],
      "metadata": {
        "id": "rdnnEH45BAwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = my_model.predict(pad_x_train)\n",
        "data_count, case_count = result.shape\n",
        "print('%d개의 훈련 데이터가 %d개의 경우의 수를 갖는다' % (data_count, case_count))\n",
        "result"
      ],
      "metadata": {
        "id": "r2CiL7jXBLWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 예측 결과를 1차원 배열로 변환"
      ],
      "metadata": {
        "id": "9XsNDmZCBY85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_results = result.flatten()\n",
        "f_results"
      ],
      "metadata": {
        "id": "zcoZfLW-BbpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) 훈련데이터의 실제 결과값과 머신러닝에 의한 예측값 비교"
      ],
      "metadata": {
        "id": "NWcmJhXKBfLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kdf = DataFrame({\n",
        "    'train': y_train,\n",
        "    'pred': np.round(f_results)\n",
        "})\n",
        "\n",
        "kdf['pred'] = kdf['pred'].astype('int')\n",
        "cm = confusion_matrix(kdf['train'], kdf['pred'])\n",
        "plt.figure(figsize=(7, 3))\n",
        "sb.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('RNN Result')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "c04rK4a0Bjwi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}